---
layout: post
title: IN PROGESS The limitations of variational models for vision-based robotics
date: 2022-11-11 11:12:00-0400
description: This blog post serves as a severely compressed version of what I did in my Master's thesis.
tags: variational-inference robotics vision-based bayesian
categories: academic
published: false
---



# Introduction
We consider the vision-based control of robots. In vision-based robotics, a robot's state is inferred from visual data and utilised in conjunction with a control strategy to carry out intended activities. There are three key elements of vision-based robot control:
- State representation learning
- Dynamical modelling
- Control strategies

These three tasks are often decoupled and determined separately. In addition to learning useful dynamical models, separating these elements requires us to learn action policies through reinforcement learning, or use model predictive control strategies. In [Jaques et al. (2021)](https://arxiv.org/abs/2006.01959), the authors argue that decoupling these elements places unnecessary computational burden on control. Instead, they propose considering them jointly, by introducing additional inductive priors that simplify downstream control. The resultant model allows us to apply well-known feedback control using the embeddings.

In the rest of this blog post, we'll briefly go over the three aforementioned things that we need to control robots from vision. We'll start with a very quick recap of basic control theory.


# Feedback control
In real robotic control scenarios where we have access to proprioceptive information, it is typical to use simple closed-loop control to direct our process variables $$y(t)$$ towards their setpoints $$r(t)$$ using the error $$e(t)$$. The process variable (also called the state) can be a scalar or vector quantity. When the state is a vector of $$\mathbb{R}^D$$, the error will also be a vector of $$\mathbb{R}^D$$; depending on the scenario this can be considered as $$D$$ parallel control loops (there might be some correlation between state variables depending on the situation)

[<img src="/assets/img/feedback.jpg" width="750"/>](/assets/img/feedback.jpg)


The typical controller used in feedback control is the proportional-integral-derivative (PID) controller:

$$
u(t) = K_\text{p} \, e(t) + K_\text{i} \, \int_0^t e(\tau) \, \text{d}\tau + K_\text{d} \, \frac{\text{d} \, e(t)}{\text{d}t} \, .
$$

The gain terms $$K_\text{p}, K_\text{i} \text{ and } K_\text{d}$$ contribute distinctively to the response of the controller: the proportional term guides the process variable directly towards its setpoint; the derivative term introduces inertia in the actuation, leading to smoother control trajectories; and the integral term is generally used to eliminate steady-state error.

The use of PID control is widespread and considered to be the golden standard for simple feedback control because it incorporates the proportional, derivative and integral modes and it is simple to implement and tune.

# Variational recurrent neural network

When the data under consideration are sequences, the variational autoencoder is not directly applicable; it must be extended to sequence modelling. The variational recurrent neural network (VRNN) as proposed in (REF), is a recurrent neural network with a variational autoencoder included at every timestep. A notable addition is that the relationship between latent variables across timesteps is also modelled. 

From this point on $$\mathbf{u}$$ denotes the actuation (in an actuated system). We have a sequence of $$T$$ images $$\mathbf{x}_{1:T}$$, actuations $$\mathbf{u}_{1:T}$$, and the corresponding latent representations of the images $$\mathbf{z}_{1:T}$$. The goal of training this model is to maximise the marginal data likelihood. The general form of the marginal data likelihood is given by:

$$
	p(\mathbf{x}_{1:T} \mid \mathbf{u}_{1:T}) = \int p(\mathbf{x}_{1:T} \mid \mathbf{z}_{1:T} , \mathbf{u}_{1:T}) p(\mathbf{z}_{1:T} \mid \mathbf{u}_{1:T}) \, \text{d}\mathbf{z}_{1:T} \, .
$$

The two terms in the integral of Equation \ref{eqn:vrnn_iml} are factorised as follows under a Markov assumption on latent states:

$$
	p(\mathbf{x}_{1:T} \mid \mathbf{z}_{1:T}, \mathbf{u}_{1:T}) = \prod_{t=1}^{T} p(\mathbf{x}_{t} \mid \mathbf{z}_{t})
$$

and,

$$
	p(\mathbf{z}_{1:T} \mid \mathbf{u}_{1:T}) = \prod_{t=1}^{T} p(\mathbf{z}_t \mid \mathbf{z}_{t-1}, \mathbf{u}_{t-1})  \, .
$$

The approximate posterior of the sequence is given by:

$$
	q(\mathbf{z}_{1:T} \mid \mathbf{x}_{1:T}) = \prod_{t=1}^{T} q(\mathbf{z}_t \mid \mathbf{x}_t, \mathbf{z}_{t-1}, \mathbf{u}_{t-1})  \, .
$$

The model is trained by maximising the variational lower bound. The objective function is the timestep-wise variational lower bound given by:

$$
	\begin{split}
		\log p_\theta(\mathbf{x}_{1:T} \mid \mathbf{u}_{1:T}) &\geq \sum_{t=1}^T \mathbb{E}_{q_\phi(\mathbf{z}_t \mid \mathbf{x}_t, \mathbf{z}_{t-1}, \mathbf{u}_{t-1})} \underbrace{\log p_\theta(\mathbf{x}_t \mid \mathbf{z}_t)}_{\text{reconstruction}} \\
		&\hspace{1.5cm} - \underbrace{\text{KL}(q_\phi(\mathbf{z}_t \mid \mathbf{x}_{t}) || p_\theta(\mathbf{z}_{t} \mid \mathbf{z}_{t-1}, \mathbf{u}_{t-1}))}_{\text{prior divergence penalty}} \, .
	\end{split}
$$

# Newtonian variational autoencoder


The Newtonian variational autoencoder proposed by (REF) addresses the loss of second-order information by introducing linear second-order dynamics (modelling on the level of acceleration) in the latent space and constraining it such that the dimensions remain disentangled. This aids in interpretability and induces a smooth latent space in which we can successfully use proportional control.

This model explicitly treats position and velocity as two separate latent variables $$\mathbf{z}$$ and $$\mathbf{v}$$. For an actuated rigid body robot of $$D$$ degrees-of-freedom and state vector $$\mathbb{R}^D$$, we model second-order latent dynamics:

$$
	\frac{\text{d}\mathbf{v}}{\text{d}t} = \mathbf{A}(\mathbf{z}, \mathbf{u})  \cdot \mathbf{z} + \mathbf{B}(\mathbf{z}, \mathbf{u}) \cdot  \mathbf{v} + \mathbf{C}(\mathbf{z}, \mathbf{u}) \cdot  \mathbf{u} \, .
$$

Only $$\mathbf{z}$$ is used as the stochastic state variable that is inferred by the approximate posterior $$\mathbf{z}_t \sim q_\phi(\mathbf{z}_t \mid \mathbf{x}_t)$$. Then $$\mathbf{v}$$ is deterministic, naturally defined as:

$$
	\mathbf{v}_t = (\mathbf{z}_t - \mathbf{z}_{t-1}) / \Delta t \, ,
$$


where $$\mathbf{z}_t \sim q_\phi(\mathbf{z}_t \mid \mathbf{x}_t)$$ and $$\mathbf{z}_{t-1} \sim q_\phi(\mathbf{z}_{t-1} \mid \mathbf{x}_{t-1})$$. 

Returning to the marginal data likelihood of the variational recurrent neural network, the generative model is once again factorised under a Markov assumption, with auxiliary latent velocity:

$$
	p(\mathbf{x}_{1:T} \mid \mathbf{z}_{1:T}, \mathbf{u}_{1:T}) = \prod_{t=1}^{T} p(\mathbf{x}_t \mid \mathbf{z}_t)
$$

and,

$$
	p(\mathbf{z}_{1:T} \mid \mathbf{u}_{1:T}; \mathbf{v}_{1:T}) = \prod_{t=1}^{T} p(\mathbf{z}_t \mid \mathbf{z}_{t-1}, \mathbf{u}_{t-1}; \mathbf{v}_t) \, .
$$

The transition prior is chosen to be a Gaussian distributed prediction from the linear dynamical system:

$$
	p(\mathbf{z}_t \mid \mathbf{z}_{t-1}, \mathbf{u}_{t-1}; \mathbf{v}_t) = \mathcal{N}(\mathbf{z}_{t}\mid \mathbf{z}_{t-1} + \Delta t \cdot \mathbf{v}_t, \sigma^2)
$$

$$
	\mathbf{v}_t = \mathbf{v}_{t-1} + \Delta t \cdot (\mathbf{A} \cdot \mathbf{z}_{t-1} + \mathbf{B} \cdot \mathbf{v}_{t-1} + \mathbf{C} \cdot \mathbf{u}_{t-1}) \, ,
$$

with $$[\mathbf{A}, \log(-\mathbf{B}), \log(\mathbf{C})] = \text{diag}(f_\psi(\mathbf{z}_t, \mathbf{u}_t))$$, and $$f_\psi$$ is a neural network. The following additional restrictions are applied:
- **Diagonal transition matrices** $$\{ \mathbf{A, B, C}\}$$ encourages correct coordinate relations because linear combinations of dimensions are eliminated.
- **B is strictly negative** to induce an inertial effect as per the intuition of velocity.
- **C is strictly positive** to ensure correct directional relations between the action $$\mathbf{u}$$ and the position $$\mathbf{z}$$.

The distributions $$p_\theta(\mathbf{x}_t \mid \mathbf{z}_t)$$ and $$q_\phi(\mathbf{z}_t \mid \mathbf{x}_t)$$ are diagonal Gaussians parameterised by neural networks.

This model is also trained by maximising the marginal likelihood of the data. The variational lower bound of this model is given by:

$$
	\begin{split}
		\log p(\mathbf{x}_{1:T} \mid \mathbf{u}_{1:T}) &\geq \sum_{t=1}^T \mathbb{E}_{q(\mathbf{z}_{t-1} \mid \mathbf{x}_{t-1}) q(\mathbf{z}_{t-2} \mid \mathbf{x}_{t-2})} \bigg( \underbrace{\mathbb{E}_{p(\mathbf{\hat{z}}_{t} \mid \mathbf{z}_{t-1}, \mathbf{u}_{t-1})} \log(\mathbf{x}_t \mid \mathbf{\hat{z}}_t)}_{\text{predicted present reconstruction}} \\
		&\hspace{2cm} -\underbrace{\text{KL}(q(\mathbf{z}_t \mid \mathbf{x}_t)||p(\mathbf{z}_t \mid \mathbf{z}_{t-1}, \mathbf{u}_{t-1})}_{\text{transition prior divergence}} \bigg)  \, .
	\end{split}
$$

It is noteworthy that this variational lower bound specifies reconstruction based on the predicted present state $$\mathbf{\hat{z}}_t$$ as per the dynamical model. This is known to place a great emphasis on the predictive capability of the dynamical model through the transition prior. 
